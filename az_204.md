AZ-204:

# Module 1: Explore Azure App Service:

1. Implement Azure App Service web apps

    - HTTP-based service for hosting web apps, REST APIS, etc. in Windows- or Linux-based environments.
    - Auto-scale of resources and container support
    - CI/CD support
    - DEV and PROD slot dep. On payment plan
    - App Service support different runtimes, check with: `az webapp list-runtimes --os-type linux`
    - A custom container option is supported, helps to avoid limits; like storage volume latency,
      it places files in the container filesystem instead of on the content volume
    -
2. Examine Azure App Service plans

    - An App Service plan defines a set of compute resources for a web app to run
    - Each App Service plan defines:

        - Operating System (Windows, Linux)
        - Region (West US, East US, etc.)
        - Number of VM instances
        - Size of VM instances (Small, Medium, Large)
        - Pricing tier: Shared, Dedicated, Isolated (runs with others, runs all yours, runs only this one app)
    - App Service Plan is a scale unit: all apps run on all VMs defined, more resources needed → isolate in a separate
      service plan

3. Deploy to App Service

    - App Service supports both automated and manual deployment
    - CI/CD from:

        - Azure DevOps Services
        - GitHub
        - BitBucket
    - Manual deployment:

        - Git URL
        - CLI: `webapp up` (can create a new app)
        - `curl`: send ZIP resources to App Service
        - FTP/S
    - Deployment slots: allows deploying to staging and swap staging and prod → swap warms up the worker
    - Container deployment:

        - Build and tag the image
        - Push the tagged image
        - Update the deployment slot with the new image tag

4. Explore authentication and authorization in App Service

    - Built-in authentication feature: supports Auth without own implementing
    - Multiple providers supported (Facebook, Googel, GitHub, any OpenID provider like Okta)
    - Any HTTP request passes through auth module:

        - Authenticates users and clients with the specified identity provider
        - Validates, stores, and refreshes OAuth tokens issued by the configured identity provider
        - Manages the authenticated session
        - Injects identity information into HTTP request headers
    - Can be configured using Azure Resource Manager settings or using a configuration file
    - Authentication flow:

        - Without provider SDK: browser apps, rendering a sign-in form from provider
        - With provider SDK: browser less apps without sig-in form from provider; manually sign-in and then submit the
          auth token to App Service for validation
    - Authorization behavior:

        - Allow unauthenticated requests
        - Require authentication
    - App Service provides a built-in token store

5. Discover App Service networking features

    - Problem: you can't connect the App Service network directly to your network (thre is not only you as a customer)
    - There are in- and outbound features to control calls to and from your app
    - Roles: fron ends (for incoming calls) and workers (for user tasks)
    - Default behavior: all apps on one worker, if scaled, all apps are replicated to a new one
    - Outbound addresses: there's a property called `possibleOutboundIpAddresses` (all possible)
      or `outboundIpAddresses` that lists them:

      ```
      az webapp show \
      --resource-group <group_name> \
      --name <app_name> \
      --query outboundIpAddresses \
      --output tsv
      ```
6. Example: creating a static HTML app and deploy to Azure App Service:

    - Using the Azure CLI command: `az webapp up`:

        - Create a default resource group if one isn't specified.
        - Create a default app service plan.
        - Create an app with the specified name.
        - Zip deploy files from the current working directory to the web app.
    - Set variables to hold the resource group and app names:
      `resourceGroup=$(az group list --query "[].{id:name}" -o tsv) appName=az204app$RANDOM`
    - Create web app: `az webapp up -g $resourceGroup -n $appName --html`

7. Deployment and scaling options:

    - Deployment slots: we need at least a standard plan
    - Slots are live apps, where we can deploy different versions of our app
    - We can have one slot each stage (DEV, STAGING, PROD)
    - Use Swaps to turn the code from f. e.
      STAGING into PROD without a new deployment.
      The advantage of this: we can
      always swap back to the previous PROD version if needed
    - We can always keep all configs using deployment slot levels (db connections, etc.)

8. Settings of web apps:

    - Under Configuration/General settings, we can adjust programming language, version, cookies, certification, etc.
    - error pages: custom HTMLs being shown by status codes
    - TLS/SSL settings and certificates: app service manages certificates for custom domains (payment required)

9. Autoscaling of web apps:

    - Two options available: scaling up or scaling out. The First one is to use a bigger machine, the second one is to
      use more machines
    - Scaling up is bounded, regardless of payment plan, so scaling out is the best way to go
    - Example: scaling out from 1 to 2: we have 2 VMs and Azure takes care of load balancing (incoming traffic is
      randomly assigned to 1 or 2)
    - Auto-scaling: based on schedule and metrics (# users, CPU %, etc.)
    - Based on metrics, we define rules on which auto-scaling is triggered
    - There is always a rule for scaling up AND scaling down required to save costs
    - We can also scale on time (9-5 Mon-Fr or so)
    - Scaling on alerts: we can programmatically set auto-scaling based on logs

10. Diagnostic logs

    - Metrics can be found in Webbapp Overview/Monitoring
    - Further down on the left Monitoring/... we find different logs
    - Alerts and Metrics are NOT covered by the exam
    - Application logs:
        - we can turn on app logging on a given level and store log files ether in filesystem or in blob
          storage
        - We can download logs using FTP(S)
        - Common exam question here: "How do you track failed requests to your web app?"
        - Answer: "By turning on Failed request tracing"
    - Diagnostic settings:
        - A way of collecting logs into analytic workspace
        - If this menu is not loading, you need to register `Microsoft.HDInsight` resource
          provider:
        - To register a subscription with Microsoft.HDInsight in Azure, follow these steps:

            1. Sign in to the Azure portal and select "Subscriptions."
            2. Choose the subscription where you want to enable the Microsoft.Insights provider.
            3. Under the "Settings" section, select "Resource providers."
            4. In the filter box, enter "insight" to find the Microsoft.Insights provider.
            5. If the status of the provider is "NotRegistered," select the Microsoft.HDInsight
               provider and then click "Register."
        - We can create a new diagnostic based on types in the list and choose destination details
    - Logs:
        - We can then run log queries under Monitoring/Logs section. There is KQL language used for that
    - Log Stream:
        - logs in real time as stream here (app logs or web server logs)

11. DEMO: Create a Web App in local PowerShell

    - open CLI and type `pwsh` to start PowerShell
    - Type get-command to list all available commands
    - Usage of wild cards: `get-command *AzWebapp`
    - Creating a new Web App:
        - Find out the current subscription id: `Get-AzSubscription`
        - Then set the subscription by using `Select-AzSubscription {subscription id}`
        - Create a new resource group: `New-AzResourceGroup -Location 'EastUS' -Name 'powershellwebapp'`
        - Create a new App Service Plan:
          `New-AzAppServicePlan -Name 'aznewweabappserviceplan1' -Location 'EastUS' -ResourceGroupName 'powershellwebapp' -Tier Free -NumberofWorkers 2 -WorkerSize "Small"`
        - If you get an unauthorized error, check your account permissions:
          `Get-AzRoleAssignment -ResourceGroupName 'powershellwebapp'` or switch to another region
        - Now create a new Web App within the Service Plan:
          `New-AzWebApp -ResourceGroupName 'powershellwebapp' -Name 'newpowershellwebapp1' -Location 'WestEurope' -AppServicePlan 'aznewweabappserviceplan1'`

12. DEMO: Create a Web App in CLI

    - We can either use Azure CLI in Azure portal or install it locally: `brew install azure-cli`
    - If we go locally, we first need to log in: `az login`
    - Create a new resource group: `az group create --name cliwebapp --location eastus`
    - Create a new App Service Plan: `az appservice plan create -g cliwebapp -n cliwebappsp234 --location westeurope`
    - Now create a new Web App within the Service Plan:
      `az webapp create -g cliwebapp -n newcliwebapp1 -p cliwebappsp234`
    - NOTE: we can use the command `az webapp up` to do all three previous steps in one
    - There is a github repo for webapp samples: https://github.com/Azure-Samples/html-docs-hello-world
    - We just create a new directory in azure and clone the repo into it:
      `git clone https://github.com/Azure-Samples/html-docs-hello-world.git`
    - We can now create a new web app based on this resource:
      `az webapp up --location westeurope --name webappfromtemplate --html`

13. Web App console

    - In Web App overview on the left under Development Tools/Console
    - We can access a CLI for diagnostics and web app managing
    - To investigate deployment status go up `cd ..` and `dir deployments`
    - Under Development Tools/Advanced Tools/Go there is an additional web site being deployment with your web app (
      KUDU: a
      “hidden” or “background “service site; it is useful for capturing memory dumps, looking at deployment logs,
      viewing configuration parameters and much more)
    - By opening the Debug console, we can navigate to web app resources, LogFiles, etc.
    - Recent path for log files etc.: cd home/site/wwwroot/

# Module 2: Containers:

- There are two parts of containers relevant for the exam: Container Instances and Container Registry
- Container Instances are just creating a single Docker container; there are options for resources like ACR (Azure
  Container Registry, Simple image or others like Docker hub)
- Container Registry is an Azure place where you can push Docker images for usage in Web apps, etc.
- NOTE: there are three service plans available and ALL are NOT for free
- Under Services/Repositories you can see all pushed images
- NOTE: Docker support is not available in Visual Studio Code under MacOS, so we just need to create a Dockerfile in the
  root directory
- We can then right clock on the Dockerfile and "Build image in Azure"
- We then find the image in the according container registry
- Enabling an admin user for ACR is required, since we need to push from CLI, etc.
    - Go to Access keys and turn on "Admin user"
- Now we are able to create a container instance from the image by creating a new container instance and selecting "from
  Container registry"
- Under Settings/Containers we have kind of logging
- We can also deploy a Web app based on image from ACR, the process is the same as creating a container instance

# Module 3: Function App:

- Function App is a set of functions
- Functions are essentially files, and so they need a storage account
- We can have different service plans, f. e. Consumption allows 1Mio executions per month for free
- Network option is only available on higher price ranges
- Functions start based on triggers like HTTP request, Timer, etc.
- We create functions within VSC by creating a workspace first and then by creating a new function
- Afterward, we can deploy to Azure and function is available in the function app overview
- We can test the function in the browser by getting the url: Get function URL/default function key
- Under Invocations, we can see the monitoring of the function runs
- Under Logs, we see a real time logging system (log stream)
- With triggers, we also have different output bindings, like Blob storage, etc.
- We can add an output under "Integration" if we click on the function in the portal (editable only if the function was
  created within the portal)
- We need to create a storage account first to push the output of the function into the storage
- NOTE: if we create the function app itself via VSC we are not able to create functions in the portal!
- Under "Integration" we can add an output as Azure Blob Storage by creating a new storage account connector according
  to the storage account we created before
- The goal is to put a file into a container "outcontainer" in the storage
- NOTE: "outcontainer" should be created BEFORE you add it as an output path
- We can create a container in the storage account by going to the resource Data Storage/Containers
- Another way to modify bindings: `function.json` file
- We can write into a container file by adding `context.bindings.outputBlob = name;` into the function code
- We can verify that by going to the storage account, "outcontainer" and look for a new file created
- Timer Trigger functions require a cron formatted timer, like `0 */5 * * * *`
- Meaning: 0. second, every 5 minutes, any hour, any day of the month, any month of the year, any day of the week,
  example: `0 * * * 12 1` (every monday in december, every second)
- Difference to the HTTP trigger: there is no external trigger like HTTP request
- To test the function, we need to add `"authLevel": "anonymous"` into the bindings in `function.json`, since we do not
  have any authentication
- Durable functions: normal triggered functions are short living with timeout about 30 minutes, so not suitable for
  long-terming tasks; for such work, Azure proposes durable functions
- They do support long-running functions (stateful), can change into frozen state by waiting for an operation being
  executed
- They can call each other
- Structure: a client (original triggered function) sets up an orchestrator (workflow step in code, like a delegate) to
  perform an activity
- Architecture patterns:
    - Function chaining pattern (chaining calls in order)
    - Fan out/in (parallel multiple executions with waiting)
    - Asynchronous API pattern (call and wait)
    - Monitor pattern (waiting for something to happen)
    - Human interaction pattern
- Set up for usage of durable functions:
    - in function app under Developer Tools/App Service Editor we open function file
      system
    - Create `package.json` for dependencies: `touch package.json` (cmd left in the bar) for `npm`:

        ```
      {
        "name": "myfunction",
        "version": "1.0.0"
      }
      ```
    - Go to Development Tools/Console and execute:

        ```
        cat package.josn
        npm install durable-functions
        ```
- We can now create a durable function from a template
- Durable function HTTP Start is a client function, which starts an orchestrator function within:

    ```
   const instanceId = await client.startNew(req.params.functionName, undefined, req.body);
   ```
- Orchestration function should be created separately; it calls an activity function multiple times in a row:

    ```
    // Replace "Hello" with the name of your Durable Activity Function.
    outputs.push(yield context.df.callActivity("Hello", "Tokyo"));
    ```
- So as the last part, we create a Durable Activity Function "Hello" to call from orchestrator:

    ```
    // NOTE: questiontext comes from function.json as binding name and can be renamed there.
    // ${context.bindings.questiontext} is actually the parameter the activity function is being called with from orchestrator.
    module.exports = async function (context) {
    return `Are you really asking me that: ${context.bindings.questiontext}?`;
    };
    ```
- Sum up: there are three durable functions-construction: Durable function HTTP Start starts Durable Orchestrator, which
  calls Durable activity function multiple times
- To test it, we just click "Get Function Url" in HTTP Start function overview (as default (function key)), replace
  `functionName` parameter with Orchestrator function name and
  execute in the browser
- Response is a bunch of urls, where `StatusQueryGetUri` returns JSON with return values
- Usage of `moment`: a dependency being installed like `durable-functions` for creating delays within function calls
- After installing, we can add a delay to the orchestrator like:

    ```
    const deadline = moment.utc(context.df.currentUtcDateTime).add(1, 'h');
    yield context.df.createTimer(deadline.toDate());
    ```
- In general, durable functions have a living time of 7 days, but with moment usage we can expand it to unlimited
- Doing so, they become stateful; Azure takes care of allocation resources between calls, so CPU usage can be more
  economical
- Code Samples: Durable Functions https://github.com/Azure-Samples/durablefunctions-apiscraping-dotnet
- Creating a function using Azure bash:
    - NOTE: first we need to install Azure Functions Core Tools: https://github.com/Azure/azure-functions-core-tools
    - Open bash in Azure
    - Create a directory: `mkdir ~/testfunction` and go to it
    - type `func init` and follow instructions to create a new function app project
    - type `func new` to create a new function from template
    - type `func start` to run the function under `localhost`
- NOTE: we can do the same process in the Azure Cloud Shell, but we need Azure Functions Core Tools to be installed
- I can deploy the function by opening the folder in VSC, switching to Azure and saying "deploy" below where the
  workspace is shown
- Alternatively: `func azure functionapp publish "name of the function"`

# Module 4: Azure Storage Accounts:

- Develop solutions, which use blob storage are in focus
- Blob storage is the least expensive way to store files within Azure
- Pay methods: per storage place and number of requests per month
- Redundancy options differ in number and location of created copies
- Additional read access is a second url pointing to the next regional copy to reduce latency
- Network access: by public access enabled, any request with access token can be provided
- Network routing: either over microsoft network or over the internet, the first one costs extra and is more secure
- Data protection:
    - soft/hard deleting (immediately, after x days)
    - point-time-restore: ability to go back to a particular date
    - Tracking: versioning of files, way of getting notification about changes
    - version-level immutability support: no way to effectively delete/change files, backup always
- Encryption:
    - It is always on, but the way where keys are storaged can be changed
    - Additional layer can be added: infrastructure encryption